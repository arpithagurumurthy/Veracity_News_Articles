{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5dS15sUva-g"
      },
      "source": [
        "Arpitha Gurumurthy </br>\n",
        "Team: Amalgam\n",
        "### **Factor:**\n",
        "Style Based approaches for fake news detection\n",
        "\n",
        "### **Micro factors for Style based:**\n",
        "* Hyperpartisan: Extremely one sided\n",
        "* Yellow Journalism: relying on eye-catching headlines\n",
        "* Deception / lying in text\n",
        "\n",
        "### **Dates:**\n",
        "Scraped on April 20th and all of the news was posted within 2 days of scraping it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7833tJBLSzG"
      },
      "source": [
        "# **Named Entity Recognition with NLTK and SpaCy**\n",
        "Named entity recognition (NER)is the first step towards information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_evd5HLjZmb1"
      },
      "source": [
        "#Importing data from google sheets - politifact dataset\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "import tensorflow.compat.v1 as tf\n",
        "r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ9xbQF0uRmyBhtehROE5uTac8JbvNd-jq-NMD99y6HVuungzxDuftmYiY74ZWrenpLyDFtGToiFeMo/pub?gid=745557768&single=true&output=csv')\n",
        "data = r.content\n",
        "df_distillation = pd.read_csv(BytesIO(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WGL00cqiMIVO",
        "outputId": "2c6d676d-0010-4f32-fafe-9bfdb6197aa4"
      },
      "source": [
        "df_distillation.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Source</th>\n",
              "      <th>Posted</th>\n",
              "      <th>Link</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Covid in Uttar Pradesh: Coronavirus overwhelms...</td>\n",
              "      <td>BBC via Yahoo News</td>\n",
              "      <td>4 hours ago</td>\n",
              "      <td>https://news.yahoo.com/covid-uttar-pradesh-cor...</td>\n",
              "      <td>Uttar Pradesh, India's most populous state, is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Man who allegedly told U.S. Olympian \"go home,...</td>\n",
              "      <td>Newsweek</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>https://www.newsweek.com/california-man-attack...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Corona man arrested after punching Asian Ameri...</td>\n",
              "      <td>KTLA-TV Los Angeles</td>\n",
              "      <td>21 hours ago</td>\n",
              "      <td>https://ktla.com/news/local-news/corona-man-ar...</td>\n",
              "      <td>A Corona man accused of physically assaulting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What should investors do after the 4600-point ...</td>\n",
              "      <td>MSN News</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>https://www.msn.com/en-in/money/topstories/wha...</td>\n",
              "      <td>© Kshitij Anand What should investors do after...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Construction starts on 91-15 freeways toll-lan...</td>\n",
              "      <td>The Press-Enterprise</td>\n",
              "      <td>18 hours ago</td>\n",
              "      <td>https://www.pe.com/2021/04/19/construction-sta...</td>\n",
              "      <td>Construction was set to start Monday night, Ap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                            Summary\n",
              "0  Covid in Uttar Pradesh: Coronavirus overwhelms...  ...  Uttar Pradesh, India's most populous state, is...\n",
              "1  Man who allegedly told U.S. Olympian \"go home,...  ...                                                NaN\n",
              "2  Corona man arrested after punching Asian Ameri...  ...  A Corona man accused of physically assaulting ...\n",
              "3  What should investors do after the 4600-point ...  ...  © Kshitij Anand What should investors do after...\n",
              "4  Construction starts on 91-15 freeways toll-lan...  ...  Construction was set to start Monday night, Ap...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oII6gV1FPffg"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb8dM5yRNpfI"
      },
      "source": [
        "## **Information Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8fYZdNnSo0H"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfLxPFiwMehK",
        "outputId": "cfc36200-603b-4c8a-eb8f-5bee01eeeae2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqT2xK1FLOlI"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSJwHM_oNGDG"
      },
      "source": [
        "df_distillation['Headline_pos_wt'] = df_distillation['Headline'].apply(lambda x: ne_chunk(pos_tag(word_tokenize(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7NAB0yTtnYs",
        "outputId": "25179eb0-684f-44be-de6a-798d1a9d0f00"
      },
      "source": [
        "df_distillation['Headline_pos_wt']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[(Covid, NNP)], (in, IN), [(Uttar, NNP)], (Pr...\n",
              "1       [(Man, NN), (who, WP), (allegedly, RB), (told,...\n",
              "2       [[(Corona, NNP)], (man, NN), (arrested, VBD), ...\n",
              "3       [(What, WP), (should, MD), (investors, NNS), (...\n",
              "4       [[(Construction, NN)], (starts, VBZ), (on, IN)...\n",
              "                              ...                        \n",
              "1356    [[(Credit, NNP)], [(Suisse, NNP)], (just, RB),...\n",
              "1357    [[(UPDATE, JJ)], (2-London, JJ), (stocks, NNS)...\n",
              "1358    [[(China, NNP)], (stocks, NNS), (fall, VBP), (...\n",
              "1359    [(GLOBAL, JJ), (MARKETS-World, NNP), (stocks, ...\n",
              "1360    [[(TFSA, NNP)], (Investing, NNP), (:, :), (2, ...\n",
              "Name: Headline_pos_wt, Length: 1361, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDENs2nANQCj"
      },
      "source": [
        "##Applying word tokenization and part-of-speech tagging to the sentence.\n",
        "def preprocess(sent):\n",
        "    sent = nltk.word_tokenize(sent)\n",
        "    sent = nltk.pos_tag(sent)\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-EH-T0dNsmB"
      },
      "source": [
        "df_distillation['Headline_pos_wt_2'] = df_distillation['Headline'].apply(lambda x: preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAhXoaqaOV2j"
      },
      "source": [
        "We get a list of tuples containing the individual words in the sentence and their associated part-of-speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNrLNebhOYio",
        "outputId": "5f93da15-5a9d-48dc-c8ad-c043bad814f4"
      },
      "source": [
        "df_distillation['Headline_pos_wt_2']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [(Covid, NNP), (in, IN), (Uttar, NNP), (Prades...\n",
              "1       [(Man, NN), (who, WP), (allegedly, RB), (told,...\n",
              "2       [(Corona, NNP), (man, NN), (arrested, VBD), (a...\n",
              "3       [(What, WP), (should, MD), (investors, NNS), (...\n",
              "4       [(Construction, NN), (starts, VBZ), (on, IN), ...\n",
              "                              ...                        \n",
              "1356    [(Credit, NNP), (Suisse, NNP), (just, RB), (pu...\n",
              "1357    [(UPDATE, JJ), (2-London, JJ), (stocks, NNS), ...\n",
              "1358    [(China, NNP), (stocks, NNS), (fall, VBP), (as...\n",
              "1359    [(GLOBAL, JJ), (MARKETS-World, NNP), (stocks, ...\n",
              "1360    [(TFSA, NNP), (Investing, NNP), (:, :), (2, CD...\n",
              "Name: Headline_pos_wt_2, Length: 1361, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LzHBvDxOnCG"
      },
      "source": [
        "## **Chunking**\n",
        "\n",
        "Now we’ll implement noun phrase chunking to identify named entities using a regular expression consisting of rules that indicate how sentences should be chunked.\n",
        "Our chunk pattern consists of one rule, that a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLtOWovNOcFx"
      },
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4P5vnP4O7kc"
      },
      "source": [
        "NPChunker = nltk.RegexpParser(pattern) \n",
        "df_distillation['Chunk_result'] = df_distillation['Headline_pos_wt_2'].apply(lambda x: NPChunker.parse(x))\n",
        "# print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB0rRaKduqav",
        "outputId": "f6d84251-a1ca-453e-b4a7-ed7bdf8c35d5"
      },
      "source": [
        "df_distillation['Chunk_result']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [(Covid, NNP), (in, IN), (Uttar, NNP), (Prades...\n",
              "1       [[(Man, NN)], (who, WP), (allegedly, RB), (tol...\n",
              "2       [(Corona, NNP), [(man, NN)], (arrested, VBD), ...\n",
              "3       [(What, WP), (should, MD), (investors, NNS), (...\n",
              "4       [[(Construction, NN)], (starts, VBZ), (on, IN)...\n",
              "                              ...                        \n",
              "1356    [(Credit, NNP), (Suisse, NNP), (just, RB), (pu...\n",
              "1357    [(UPDATE, JJ), (2-London, JJ), (stocks, NNS), ...\n",
              "1358    [(China, NNP), (stocks, NNS), (fall, VBP), (as...\n",
              "1359    [(GLOBAL, JJ), (MARKETS-World, NNP), (stocks, ...\n",
              "1360    [(TFSA, NNP), (Investing, NNP), (:, :), (2, CD...\n",
              "Name: Chunk_result, Length: 1361, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0IkDqZnuIbJ"
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "\n",
        "df_distillation['iob_tagged'] = df_distillation['Chunk_result'].apply(lambda x: tree2conlltags(x)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwDTHxkMu-CS",
        "outputId": "fd4f55f9-4bdc-43d5-dd7d-13790fa48311"
      },
      "source": [
        "df_distillation['iob_tagged']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [(Covid, NNP, O), (in, IN, O), (Uttar, NNP, O)...\n",
              "1       [(Man, NN, B-NP), (who, WP, O), (allegedly, RB...\n",
              "2       [(Corona, NNP, O), (man, NN, B-NP), (arrested,...\n",
              "3       [(What, WP, O), (should, MD, O), (investors, N...\n",
              "4       [(Construction, NN, B-NP), (starts, VBZ, O), (...\n",
              "                              ...                        \n",
              "1356    [(Credit, NNP, O), (Suisse, NNP, O), (just, RB...\n",
              "1357    [(UPDATE, JJ, O), (2-London, JJ, O), (stocks, ...\n",
              "1358    [(China, NNP, O), (stocks, NNS, O), (fall, VBP...\n",
              "1359    [(GLOBAL, JJ, O), (MARKETS-World, NNP, O), (st...\n",
              "1360    [(TFSA, NNP, O), (Investing, NNP, O), (:, :, O...\n",
              "Name: iob_tagged, Length: 1361, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp-VPm6vvBRA",
        "outputId": "d5273ad0-68d1-41f1-a3cf-e305b22ff874"
      },
      "source": [
        "df_distillation['iob_tagged'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Man', 'NN', 'B-NP'),\n",
              " ('who', 'WP', 'O'),\n",
              " ('allegedly', 'RB', 'O'),\n",
              " ('told', 'VBD', 'O'),\n",
              " ('U.S.', 'NNP', 'O'),\n",
              " ('Olympian', 'NNP', 'O'),\n",
              " ('``', '``', 'O'),\n",
              " ('go', 'VB', 'O'),\n",
              " ('home', 'NN', 'B-NP'),\n",
              " (',', ',', 'O'),\n",
              " (\"''\", \"''\", 'O'),\n",
              " ('punched', 'VBD', 'O'),\n",
              " ('couple', 'NN', 'B-NP'),\n",
              " (',', ',', 'O'),\n",
              " ('is', 'VBZ', 'O'),\n",
              " ('arrested', 'VBN', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDn-xoKFxVCE"
      },
      "source": [
        "## **Alternative way - Trial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzTNyuRuxNvN"
      },
      "source": [
        "##TESTING\n",
        "my_sent = \"WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE6-ufVJM6Ga",
        "outputId": "1d3cbd5b-ec70-4ebb-bd67-9d10b0be9f0d"
      },
      "source": [
        "##TESTING\n",
        "for sent in nltk.sent_tokenize(my_sent):\n",
        "   chunklist = []\n",
        "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "      if hasattr(chunk, 'label'):\n",
        "      #  print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
        "        chunkstr = ' '.join(c[0] for c in chunk)\n",
        "        chunkfinal = chunkstr + \":\" + chunk.label()\n",
        "        chunklist.append(chunkfinal)\n",
        "   print(chunklist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['WASHINGTON:GPE', 'New York:GPE', 'Loretta E. Lynch:PERSON', 'Brooklyn:GPE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l727Q9ArxMao"
      },
      "source": [
        "##Defining a function to label the word tokens with named enetities\n",
        "def ner(headline):\n",
        "  for sent in nltk.sent_tokenize(headline):\n",
        "    ##Appending all the word tokens and lables to a list\n",
        "    chunklist = []\n",
        "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "      if hasattr(chunk, 'label'):\n",
        "        # print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
        "        # print(\"-----------------------------------------\")\n",
        "        chunkstr = ' '.join(c[0] for c in chunk)\n",
        "        chunkfinal = chunkstr + \":\" + chunk.label()\n",
        "        chunklist.append(chunkfinal)\n",
        "    return chunklist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODtfs52TqWz"
      },
      "source": [
        "##To calculate the number of GPEs in each headline\n",
        "def gpe_count(headline):\n",
        "  for sent in nltk.sent_tokenize(headline):\n",
        "    count = 0\n",
        "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "      if hasattr(chunk, 'label'):\n",
        "        if (chunk.label() == 'GPE'):\n",
        "          count = count + 1\n",
        "    return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S-NObvkT-Fd"
      },
      "source": [
        "##Storing the named entity-GPE count as a feature in the dataframe\n",
        "df_distillation['gpe_count'] = df_distillation['Headline'].apply(lambda x: gpe_count(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQVF9YGIUCsw",
        "outputId": "b290d92f-302a-41cd-f877-9a22ca79ce41"
      },
      "source": [
        "df_distillation['gpe_count']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       3\n",
              "1       1\n",
              "2       5\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1356    0\n",
              "1357    1\n",
              "1358    1\n",
              "1359    0\n",
              "1360    0\n",
              "Name: gpe_count, Length: 1361, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnOu3mpsMFXN"
      },
      "source": [
        "##Storing the list of word token and their named entities as a feature\n",
        "df_distillation['ner'] = df_distillation['Headline'].apply(lambda x: ner(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSZN6GfhMcmx",
        "outputId": "7994730d-5f04-4c74-984d-e709c2273351"
      },
      "source": [
        "print(df_distillation['ner'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                       [Covid:GPE, Uttar:GPE, India:GPE]\n",
            "1                                              [U.S.:GPE]\n",
            "2       [Corona:GPE, Asian:GPE, American:GPE, U.S.:GPE...\n",
            "3                                            [Sensex:GPE]\n",
            "4                          [Construction:GSP, Corona:GPE]\n",
            "                              ...                        \n",
            "1356                 [Credit:ORGANIZATION, Suisse:PERSON]\n",
            "1357                     [UPDATE:ORGANIZATION, Tesco:GPE]\n",
            "1358                        [China:GPE, GDP:ORGANIZATION]\n",
            "1359                                                   []\n",
            "1360        [TFSA:ORGANIZATION, Motley Fool:ORGANIZATION]\n",
            "Name: ner, Length: 1361, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuWgtC3sNwN0",
        "outputId": "05f42aef-1cb0-469a-f467-1035462d2ff8"
      },
      "source": [
        "##Verification - 1 \n",
        "print(df_distillation['ner'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Covid:GPE', 'Uttar:GPE', 'India:GPE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-DFfNoZb3R",
        "outputId": "2242a8e6-0e6d-4d73-d2c1-88cb60c550d3"
      },
      "source": [
        "##Verification - 2\n",
        "print(df_distillation['gpe_count'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLpV4AtPLnhS"
      },
      "source": [
        "## **References :**\n",
        "* https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n",
        "* https://github.com/susanli2016/NLP-with-Python/blob/master/NER_NLTK_Spacy.ipynb\n",
        "\n",
        "NOTES\n",
        "* https://www.freecodecamp.org/news/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24\n",
        "* https://www.analyticsvidhya.com/blog/2021/05/top-8-python-libraries-for-natural-language-processing-nlp-in-2021/"
      ]
    }
  ]
}