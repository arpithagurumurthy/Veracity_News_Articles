{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl3-jAXer92_"
      },
      "source": [
        "Arpitha Gurumurthy </br>\n",
        "Team: Amalgam\n",
        "### **Factor:**\n",
        "Style Based approaches for fake news detection\n",
        "\n",
        "### **Micro factors for Style based:**\n",
        "* Hyperpartisan: Extremely one sided\n",
        "* Yellow Journalism: relying on eye-catching headlines\n",
        "* Deception / lying in text\n",
        "\n",
        "### **Dates:**\n",
        "Scraped on April 20th and all of the news was posted within 2 days of scraping it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BviIUJderyld"
      },
      "source": [
        "# **Topic Modeling and Latent Dirichlet Allocation (LDA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djza3Um9l6Ig"
      },
      "source": [
        "#Importing data from google sheets - politifact dataset\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "import tensorflow.compat.v1 as tf\n",
        "r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ9xbQF0uRmyBhtehROE5uTac8JbvNd-jq-NMD99y6HVuungzxDuftmYiY74ZWrenpLyDFtGToiFeMo/pub?gid=745557768&single=true&output=csv')\n",
        "data = r.content\n",
        "df_distillation = pd.read_csv(BytesIO(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "UgaSK9rXmU1S",
        "outputId": "2f8ed7c4-6b2c-40b3-a7d8-b85b1dd9ebba"
      },
      "source": [
        "df_distillation.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Source</th>\n",
              "      <th>Posted</th>\n",
              "      <th>Link</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Covid in Uttar Pradesh: Coronavirus overwhelms...</td>\n",
              "      <td>BBC via Yahoo News</td>\n",
              "      <td>4 hours ago</td>\n",
              "      <td>https://news.yahoo.com/covid-uttar-pradesh-cor...</td>\n",
              "      <td>Uttar Pradesh, India's most populous state, is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Man who allegedly told U.S. Olympian \"go home,...</td>\n",
              "      <td>Newsweek</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>https://www.newsweek.com/california-man-attack...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Corona man arrested after punching Asian Ameri...</td>\n",
              "      <td>KTLA-TV Los Angeles</td>\n",
              "      <td>21 hours ago</td>\n",
              "      <td>https://ktla.com/news/local-news/corona-man-ar...</td>\n",
              "      <td>A Corona man accused of physically assaulting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What should investors do after the 4600-point ...</td>\n",
              "      <td>MSN News</td>\n",
              "      <td>6 hours ago</td>\n",
              "      <td>https://www.msn.com/en-in/money/topstories/wha...</td>\n",
              "      <td>© Kshitij Anand What should investors do after...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Construction starts on 91-15 freeways toll-lan...</td>\n",
              "      <td>The Press-Enterprise</td>\n",
              "      <td>18 hours ago</td>\n",
              "      <td>https://www.pe.com/2021/04/19/construction-sta...</td>\n",
              "      <td>Construction was set to start Monday night, Ap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                            Summary\n",
              "0  Covid in Uttar Pradesh: Coronavirus overwhelms...  ...  Uttar Pradesh, India's most populous state, is...\n",
              "1  Man who allegedly told U.S. Olympian \"go home,...  ...                                                NaN\n",
              "2  Corona man arrested after punching Asian Ameri...  ...  A Corona man accused of physically assaulting ...\n",
              "3  What should investors do after the 4600-point ...  ...  © Kshitij Anand What should investors do after...\n",
              "4  Construction starts on 91-15 freeways toll-lan...  ...  Construction was set to start Monday night, Ap...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC1m8m1osmm8",
        "outputId": "7f2d31b4-77fb-45a8-c6e6-870741738c89"
      },
      "source": [
        "df_distillation['Posted'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['4 hours ago', '2 hours ago', '21 hours ago', '6 hours ago',\n",
              "       '18 hours ago', '22 hours ago', '13 hours ago', '17 hours ago',\n",
              "       '5 days ago', '4 days ago', '1 day ago', '5 hours ago',\n",
              "       '24 hours ago', '10 hours ago', '6 days ago', '10 minutes ago',\n",
              "       '2 days ago', '3 days ago', '7 days ago', '16 hours ago',\n",
              "       '11 hours ago', '12 hours ago', '7 hours ago', '3 hours ago',\n",
              "       '9 hours ago', '20 hours ago', '14 hours ago', '15 hours ago',\n",
              "       '23 hours ago', '19 hours ago', '8 hours ago', 'Posted',\n",
              "       '1 hour ago', '55 minutes ago', '49 minutes ago', '50 minutes ago',\n",
              "       '7 minutes ago', '19 minutes ago', '35 minutes ago'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlHmW4cJc0_5"
      },
      "source": [
        "## **Data Pre-processing**\n",
        "We will perform the following steps:\n",
        "* Tokenization: Splitting the text into sentences and the sentences into words. Lowercasing the words and removing punctuation.\n",
        "* Words that have fewer than 3 characters are removed.\n",
        "* All stopwords are removed.\n",
        "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
        "* Words are stemmed — words are reduced to their root form.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0STKpRumfrX",
        "outputId": "bbdf967b-4202-4977-b33c-238bdd81cd02"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiDv97mAn3lk"
      },
      "source": [
        "from nltk import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g45MSa8mhN1"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return PorterStemmer().stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woAa2OhWmp2g",
        "outputId": "4bc7bdd9-a2b0-423d-a325-1287a89c429e"
      },
      "source": [
        "##Testing the above function on a sample document\n",
        "doc_sample = df_distillation['Headline'][0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['Covid', 'in', 'Uttar', 'Pradesh:', 'Coronavirus', 'overwhelms', \"India's\", 'most', 'populous', 'state']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['covid', 'uttar', 'pradesh', 'coronaviru', 'overwhelm', 'india', 'popul', 'state']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqkDgLjSoJkS",
        "outputId": "786c015e-0d42-4598-e65d-ea920b139326"
      },
      "source": [
        "##saving the preprocessed headline text as ‘processed_docs’\n",
        "processed_docs = df_distillation['Headline'].map(preprocess)\n",
        "processed_docs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [covid, uttar, pradesh, coronaviru, overwhelm,...\n",
              "1    [allegedli, tell, olympian, home, punch, coupl...\n",
              "2    [corona, arrest, punch, asian, american, coupl...\n",
              "3                      [investor, point, fall, sensex]\n",
              "4    [construct, start, freeway, toll, lane, connec...\n",
              "5    [arrest, allegedli, assault, elderli, korean, ...\n",
              "6    [constel, brand, domin, beer, market, motley, ...\n",
              "7    [patrol, recruit, program, whitfield, sheriff,...\n",
              "8    [corona, accus, sexual, exploit, girl, arraign...\n",
              "9    [caption, stay, home, dalam, bahasa, inggri, b...\n",
              "Name: Headline, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9YP1-Y6osQA"
      },
      "source": [
        "## **Bag of Words on the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_wm8nUpoxXt",
        "outputId": "a218687c-4fe3-4b49-df9e-d9cd87892dae"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 coronaviru\n",
            "1 covid\n",
            "2 india\n",
            "3 overwhelm\n",
            "4 popul\n",
            "5 pradesh\n",
            "6 state\n",
            "7 uttar\n",
            "8 allegedli\n",
            "9 arrest\n",
            "10 coupl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zLGnzQnTbr"
      },
      "source": [
        "**Gensim filter_extremes:**\n",
        "Filtering out tokens that appear in-\n",
        "* less than 15 documents (absolute number) or\n",
        "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
        "* after the above two steps, keeping only the first 100000 most frequent tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiPt4TVCpjtb"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq3NMdWmnxTA",
        "outputId": "daf9e4a6-a751-4290-da0a-e57599ac23f1"
      },
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 covid\n",
            "1 state\n",
            "2 arrest\n",
            "3 american\n",
            "4 corona\n",
            "5 investor\n",
            "6 start\n",
            "7 fool\n",
            "8 market\n",
            "9 motley\n",
            "10 draft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xva1pPAoVPy"
      },
      "source": [
        "**Gensim doc2bow**\n",
        "For each document we create a dictionary reporting how many\n",
        "words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s9E3uGKpmuG",
        "outputId": "7d2249db-75d5-434e-f973-301d978eda79"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATXxdDauorfF"
      },
      "source": [
        "Preview Bag Of Words for our sample preprocessed document.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf9_Any2o5bx",
        "outputId": "7e38beee-0ab2-42ca-b27a-ef3c294d01de"
      },
      "source": [
        "processed_docs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['covid',\n",
              " 'uttar',\n",
              " 'pradesh',\n",
              " 'coronaviru',\n",
              " 'overwhelm',\n",
              " 'india',\n",
              " 'popul',\n",
              " 'state']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz-ZmyfopuSJ",
        "outputId": "20687301-9873-428e-aa37-12f56f299eff"
      },
      "source": [
        "bow_doc_0 = bow_corpus[0]\n",
        "\n",
        "for i in range(len(bow_doc_0)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
        "                                                     dictionary[bow_doc_0[i][0]], \n",
        "                                                     bow_doc_0[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 0 (\"covid\") appears 1 time.\n",
            "Word 1 (\"state\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddh9A5tCqN8k"
      },
      "source": [
        "## **TF-IDF**\n",
        "Creating a tf-idf model object using models.TfidfModel on ‘bow_corpus’ and saving it to ‘tfidf’, then applying transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qD1ydyqQ-g"
      },
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuSbnlkLqVPQ"
      },
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVd_Bn6PqUK4",
        "outputId": "ac6f46ee-d8da-4193-dc76-a17db6c5f706"
      },
      "source": [
        "len(corpus_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdHxTgavqeNU",
        "outputId": "db7df51b-4c95-44af-f7f3-cfd1ecada19c"
      },
      "source": [
        "corpus_tfidf[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.6055853562256109), (1, 0.7957803568354147)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjRz4z2kqiTy"
      },
      "source": [
        "## **Running LDA using Bag of Words**\n",
        "Training our lda model using gensim.models.LdaMulticore and saving it to ‘lda_model’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTk6ZPQpqlIA"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AsWtqofq0Oe"
      },
      "source": [
        "For each topic, we will explore the words occuring in that topic and its relative weight.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvuDihDCqoMK",
        "outputId": "90445801-1f81-4785-b025-5c36f800daeb"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.180*\"polit\" + 0.128*\"stock\" + 0.093*\"watch\" + 0.058*\"want\" + 0.054*\"invest\" + 0.052*\"april\" + 0.049*\"sport\" + 0.043*\"favr\" + 0.043*\"brett\" + 0.040*\"news\"\n",
            "Topic: 1 \n",
            "Words: 0.208*\"stock\" + 0.092*\"earn\" + 0.088*\"rise\" + 0.060*\"reuter\" + 0.052*\"record\" + 0.034*\"world\" + 0.033*\"gain\" + 0.030*\"say\" + 0.027*\"strong\" + 0.026*\"high\"\n",
            "Topic: 2 \n",
            "Words: 0.115*\"open\" + 0.095*\"stock\" + 0.083*\"lower\" + 0.068*\"year\" + 0.067*\"season\" + 0.063*\"arrest\" + 0.054*\"record\" + 0.040*\"index\" + 0.039*\"high\" + 0.039*\"close\"\n",
            "Topic: 3 \n",
            "Words: 0.104*\"covid\" + 0.093*\"vaccin\" + 0.092*\"school\" + 0.072*\"polit\" + 0.070*\"high\" + 0.059*\"state\" + 0.037*\"sport\" + 0.036*\"stock\" + 0.032*\"april\" + 0.028*\"mix\"\n",
            "Topic: 4 \n",
            "Words: 0.139*\"draft\" + 0.109*\"prospect\" + 0.107*\"stock\" + 0.064*\"viru\" + 0.053*\"surg\" + 0.050*\"biden\" + 0.048*\"hospit\" + 0.041*\"amid\" + 0.038*\"covid\" + 0.030*\"polit\"\n",
            "Topic: 5 \n",
            "Words: 0.293*\"stock\" + 0.065*\"high\" + 0.056*\"motley\" + 0.056*\"fool\" + 0.054*\"record\" + 0.034*\"best\" + 0.023*\"dividend\" + 0.023*\"european\" + 0.021*\"earn\" + 0.018*\"market\"\n",
            "Topic: 6 \n",
            "Words: 0.308*\"polit\" + 0.054*\"week\" + 0.052*\"die\" + 0.040*\"biden\" + 0.032*\"sport\" + 0.031*\"great\" + 0.025*\"stock\" + 0.025*\"reuter\" + 0.023*\"brett\" + 0.023*\"favr\"\n",
            "Topic: 7 \n",
            "Words: 0.190*\"stock\" + 0.081*\"trade\" + 0.073*\"invest\" + 0.067*\"tech\" + 0.062*\"close\" + 0.060*\"higher\" + 0.041*\"american\" + 0.037*\"democrat\" + 0.035*\"energi\" + 0.031*\"report\"\n",
            "Topic: 8 \n",
            "Words: 0.111*\"mondal\" + 0.109*\"presid\" + 0.108*\"die\" + 0.107*\"walter\" + 0.098*\"vice\" + 0.064*\"carter\" + 0.055*\"news\" + 0.050*\"stock\" + 0.041*\"vote\" + 0.040*\"strong\"\n",
            "Topic: 9 \n",
            "Words: 0.136*\"stock\" + 0.075*\"wall\" + 0.063*\"start\" + 0.062*\"earn\" + 0.062*\"corona\" + 0.061*\"street\" + 0.056*\"bank\" + 0.052*\"crash\" + 0.038*\"lead\" + 0.026*\"reuter\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLYa3aolrW0H"
      },
      "source": [
        "## **Running LDA using TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmCRNjEVrZhz"
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-6Cwf0qrgQB",
        "outputId": "e96a0338-d12e-4957-efc4-abc91ff49483"
      },
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.101*\"watch\" + 0.071*\"mondal\" + 0.066*\"walter\" + 0.060*\"rise\" + 0.059*\"stock\" + 0.057*\"vice\" + 0.057*\"presid\" + 0.054*\"die\" + 0.040*\"carter\" + 0.037*\"april\"\n",
            "Topic: 1 Word: 0.134*\"draft\" + 0.092*\"prospect\" + 0.072*\"stock\" + 0.065*\"earn\" + 0.043*\"news\" + 0.039*\"look\" + 0.038*\"invest\" + 0.033*\"tech\" + 0.030*\"bank\" + 0.028*\"european\"\n",
            "Topic: 2 Word: 0.245*\"stock\" + 0.055*\"motley\" + 0.055*\"fool\" + 0.053*\"energi\" + 0.036*\"wall\" + 0.033*\"bank\" + 0.032*\"mix\" + 0.029*\"street\" + 0.027*\"reuter\" + 0.023*\"record\"\n",
            "Topic: 3 Word: 0.082*\"say\" + 0.067*\"viru\" + 0.056*\"american\" + 0.043*\"amid\" + 0.042*\"report\" + 0.040*\"democrat\" + 0.038*\"polit\" + 0.037*\"surg\" + 0.036*\"earn\" + 0.034*\"stock\"\n",
            "Topic: 4 Word: 0.064*\"pandem\" + 0.061*\"april\" + 0.050*\"share\" + 0.050*\"gain\" + 0.050*\"start\" + 0.049*\"china\" + 0.045*\"world\" + 0.043*\"data\" + 0.043*\"stock\" + 0.039*\"record\"\n",
            "Topic: 5 Word: 0.071*\"vote\" + 0.061*\"trade\" + 0.058*\"close\" + 0.055*\"record\" + 0.051*\"stock\" + 0.048*\"lower\" + 0.047*\"pull\" + 0.047*\"high\" + 0.044*\"biden\" + 0.035*\"lead\"\n",
            "Topic: 6 Word: 0.079*\"invest\" + 0.069*\"stock\" + 0.064*\"right\" + 0.046*\"higher\" + 0.044*\"covid\" + 0.044*\"growth\" + 0.040*\"high\" + 0.036*\"fool\" + 0.036*\"motley\" + 0.034*\"econom\"\n",
            "Topic: 7 Word: 0.257*\"polit\" + 0.087*\"covid\" + 0.079*\"week\" + 0.052*\"season\" + 0.050*\"biden\" + 0.044*\"open\" + 0.032*\"lead\" + 0.028*\"sport\" + 0.027*\"brett\" + 0.027*\"favr\"\n",
            "Topic: 8 Word: 0.117*\"state\" + 0.090*\"school\" + 0.075*\"year\" + 0.070*\"high\" + 0.068*\"arrest\" + 0.058*\"crash\" + 0.042*\"die\" + 0.037*\"ralli\" + 0.037*\"presid\" + 0.030*\"american\"\n",
            "Topic: 9 Word: 0.180*\"vaccin\" + 0.095*\"best\" + 0.093*\"time\" + 0.072*\"polit\" + 0.061*\"stock\" + 0.058*\"dividend\" + 0.036*\"mix\" + 0.025*\"covid\" + 0.024*\"close\" + 0.021*\"latest\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpehX0M9rHaA"
      },
      "source": [
        "**Performance evaluation by classifying sample document using LDA Bag of Words model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq2InyvHruxQ",
        "outputId": "26a4e792-4b60-4aa1-c1be-7b8183fefd3c"
      },
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.4570715129375458\t \n",
            "Topic: 0.117*\"state\" + 0.090*\"school\" + 0.075*\"year\" + 0.070*\"high\" + 0.068*\"arrest\" + 0.058*\"crash\" + 0.042*\"die\" + 0.037*\"ralli\" + 0.037*\"presid\" + 0.030*\"american\"\n",
            "\n",
            "Score: 0.2762371599674225\t \n",
            "Topic: 0.257*\"polit\" + 0.087*\"covid\" + 0.079*\"week\" + 0.052*\"season\" + 0.050*\"biden\" + 0.044*\"open\" + 0.032*\"lead\" + 0.028*\"sport\" + 0.027*\"brett\" + 0.027*\"favr\"\n",
            "\n",
            "Score: 0.033342018723487854\t \n",
            "Topic: 0.079*\"invest\" + 0.069*\"stock\" + 0.064*\"right\" + 0.046*\"higher\" + 0.044*\"covid\" + 0.044*\"growth\" + 0.040*\"high\" + 0.036*\"fool\" + 0.036*\"motley\" + 0.034*\"econom\"\n",
            "\n",
            "Score: 0.03333877772092819\t \n",
            "Topic: 0.180*\"vaccin\" + 0.095*\"best\" + 0.093*\"time\" + 0.072*\"polit\" + 0.061*\"stock\" + 0.058*\"dividend\" + 0.036*\"mix\" + 0.025*\"covid\" + 0.024*\"close\" + 0.021*\"latest\"\n",
            "\n",
            "Score: 0.03333811089396477\t \n",
            "Topic: 0.134*\"draft\" + 0.092*\"prospect\" + 0.072*\"stock\" + 0.065*\"earn\" + 0.043*\"news\" + 0.039*\"look\" + 0.038*\"invest\" + 0.033*\"tech\" + 0.030*\"bank\" + 0.028*\"european\"\n",
            "\n",
            "Score: 0.03333691135048866\t \n",
            "Topic: 0.082*\"say\" + 0.067*\"viru\" + 0.056*\"american\" + 0.043*\"amid\" + 0.042*\"report\" + 0.040*\"democrat\" + 0.038*\"polit\" + 0.037*\"surg\" + 0.036*\"earn\" + 0.034*\"stock\"\n",
            "\n",
            "Score: 0.033334724605083466\t \n",
            "Topic: 0.064*\"pandem\" + 0.061*\"april\" + 0.050*\"share\" + 0.050*\"gain\" + 0.050*\"start\" + 0.049*\"china\" + 0.045*\"world\" + 0.043*\"data\" + 0.043*\"stock\" + 0.039*\"record\"\n",
            "\n",
            "Score: 0.033334020525217056\t \n",
            "Topic: 0.245*\"stock\" + 0.055*\"motley\" + 0.055*\"fool\" + 0.053*\"energi\" + 0.036*\"wall\" + 0.033*\"bank\" + 0.032*\"mix\" + 0.029*\"street\" + 0.027*\"reuter\" + 0.023*\"record\"\n",
            "\n",
            "Score: 0.03333346173167229\t \n",
            "Topic: 0.101*\"watch\" + 0.071*\"mondal\" + 0.066*\"walter\" + 0.060*\"rise\" + 0.059*\"stock\" + 0.057*\"vice\" + 0.057*\"presid\" + 0.054*\"die\" + 0.040*\"carter\" + 0.037*\"april\"\n",
            "\n",
            "Score: 0.03333333507180214\t \n",
            "Topic: 0.071*\"vote\" + 0.061*\"trade\" + 0.058*\"close\" + 0.055*\"record\" + 0.051*\"stock\" + 0.048*\"lower\" + 0.047*\"pull\" + 0.047*\"high\" + 0.044*\"biden\" + 0.035*\"lead\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3HVggtitI2b"
      },
      "source": [
        "## **References:**\n",
        "* https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb\n",
        "* https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
        "* https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
        "\n",
        "NOTES:\n",
        "* Knowledge graph: https://programmerbackpack.com/python-knowledge-graph-understanding-semantic-relationships/\n",
        "* http://www.martingrandjean.ch/network-visualization-shakespeare/\n",
        "* question answering: https://towardsdatascience.com/question-answering-with-pretrained-transformers-using-pytorch-c3e7a44b4012"
      ]
    }
  ]
}